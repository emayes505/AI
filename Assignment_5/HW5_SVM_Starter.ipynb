{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 — SVM on LFW (Linear & RBF) + Optional PCA\n",
    "\n",
    "This starter notebook is intentionally **incomplete**. Your tasks include:\n",
    "- Load **LFW** (identities ≥ 50 images) and build a **60/15/25** train/val/test split (fixed seed).\n",
    "- Implement evaluation utilities and tuning loops for **Linear SVM** and **RBF SVM**.\n",
    "- (Optional) Add **PCA → SVM** experiments.\n",
    "- Report **validation-selected** hyperparameters and **test accuracy**.\n",
    "\n",
    "> You **may** use scikit-learn (e.g., `SVC`, `Pipeline`, `StandardScaler`, `PCA`).\n",
    "> \n",
    "> **Important:** Tune hyperparameters on the **validation** set only; after choosing best params, retrain on **train+val** and evaluate once on **test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load LFW people (min_faces_per_person=50) and flatten\n",
    "\n",
    "**Provided** so everyone uses the same filtered dataset.\n",
    "\n",
    "**Hint:** This may download on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw = fetch_lfw_people(min_faces_per_person=50, resize=0.4, color=False)\n",
    "X_images = lfw.images                 # (n_samples, h, w)\n",
    "X = lfw.data.astype(np.float32)       # (n_samples, h*w)\n",
    "y = lfw.target                        # integer labels\n",
    "target_names = lfw.target_names       # label -> name mapping\n",
    "h, w = lfw.images.shape[1:3]\n",
    "\n",
    "print(\"Images:\", X_images.shape, \"| Flattened:\", X.shape, \"| Labels:\", y.shape)\n",
    "print(\"Num classes:\", len(target_names), \"Names:\", list(target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Visualize some faces (optional but recommended)\n",
    "\n",
    "Use the helper below to display a few samples to sanity-check the data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_faces(images, labels, label_names, n_row=2, n_col=5, title=None):\n",
    "    plt.figure(figsize=(1.8*n_col, 2.2*n_row))\n",
    "    if title:\n",
    "        plt.suptitle(title)\n",
    "    for i in range(n_row*n_col):\n",
    "        plt.subplot(n_row, n_col, i+1)\n",
    "        plt.imshow(images[i], cmap=\"gray\")\n",
    "        plt.title(str(label_names[labels[i]]), fontsize=9)\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to preview\n",
    "# plot_faces(X_images[:10], y[:10], target_names, n_row=2, n_col=5, title=\"Sample faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Stratified split: 60% train / 15% val / 25% test\n",
    "\n",
    "**Provided** code for the two-stage split; keep the same seed for fairness and reproducibility.\n",
    "\n",
    "**Hint:** Use `stratify=` so class proportions are preserved in splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: train+val vs test (25% test)\n",
    "X_trval, X_te, y_trval, y_te = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "# Step 2: train vs val (20% of trval -> 15% overall)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_trval, y_trval, test_size=0.20, stratify=y_trval, random_state=RANDOM_STATE\n",
    ")\n",
    "print(\"Train:\", X_tr.shape, \"Val:\", X_val.shape, \"Test:\", X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Utilities — **YOU implement** evaluation & plots\n",
    "\n",
    "**TODO A:** Implement `evaluate_model` that:\n",
    "1. **Fits** the model on **TRAIN** only.\n",
    "2. Predicts on **VAL** and **TEST**.\n",
    "3. Returns a dict with `val_acc`, `test_acc`, and predictions.\n",
    "\n",
    "**TODO B (optional):** Implement `show_confusion` to display a confusion matrix.\n",
    "\n",
    "**Hints:**\n",
    "- Use `accuracy_score` from `sklearn.metrics`.\n",
    "- Return a dict so you can compare results across hyperparameters.\n",
    "- Keep function signatures unchanged for reuse later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_tr, y_tr, X_val, y_val, X_te, y_te, label=\"\"):\n",
    "    \"\"\"Fit on TRAIN only; eval on VAL and TEST; return metrics dict.\n",
    "    TODO: implement steps described above.\n",
    "    \"\"\"\n",
    "    #### YOUR CODE HERE ####\n",
    "    # Example sketch:\n",
    "    # clf.fit(X_tr, y_tr)\n",
    "    # val_pred = clf.predict(X_val)\n",
    "    # test_pred = clf.predict(X_te)\n",
    "    # val_acc = accuracy_score(y_val, val_pred)\n",
    "    # test_acc = accuracy_score(y_te, test_pred)\n",
    "    # print(f\"[{label}] Val Acc: {val_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    # return {\"val_acc\": val_acc, \"test_acc\": test_acc, \"val_pred\": val_pred, \"test_pred\": test_pred}\n",
    "    raise NotImplementedError(\"Implement evaluate_model as described in the cell above.\")\n",
    "\n",
    "def show_confusion(y_true, y_pred, label_names, title=\"Confusion matrix\"):\n",
    "    \"\"\"Optional helper to plot confusion matrix.\n",
    "    TODO: implement if you want to visualize per-class performance.\n",
    "    \"\"\"\n",
    "    #### YOUR CODE HERE (optional) ####\n",
    "    # disp = ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=label_names, xticks_rotation=90)\n",
    "    # plt.title(title)\n",
    "    # plt.tight_layout(); plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Linear SVM — **YOU implement** tuning over C on validation\n",
    "\n",
    "**Goal:** Build a pipeline `StandardScaler → SVC(kernel='linear')` and tune **C** on the validation set.\n",
    "\n",
    "**TODO C:** Write the loop over a small grid of `C` values, call `evaluate_model`, and track the best by **validation accuracy**.\n",
    "\n",
    "**TODO D:** After selecting the best `C`, **retrain on TRAIN+VAL** and evaluate once on **TEST**.\n",
    "\n",
    "**Hints:**\n",
    "- Use `Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='linear', C=C))])`.\n",
    "- For retraining on train+val, stack arrays: `np.vstack([X_tr, X_val])`, `np.hstack([y_tr, y_val])`.\n",
    "- Keep a clear printout of your chosen best C and corresponding accuracies.\n",
    "- Example grid: `[0.01, 0.1, 1, 10, 100]` (you can adjust)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid_linear = [0.01, 0.1, 1, 10, 100]  # you may modify\n",
    "\n",
    "best_linear = None\n",
    "best_C = None\n",
    "\n",
    "#### YOUR CODE HERE (TODO C): build loop over C, construct pipeline, call evaluate_model, track best by val_acc ####\n",
    "raise NotImplementedError(\"Implement Linear SVM tuning loop over C and select best by validation accuracy.\")\n",
    "\n",
    "# (TODO D) Retrain best Linear SVM on TRAIN+VAL and evaluate on TEST\n",
    "#### YOUR CODE HERE ####\n",
    "raise NotImplementedError(\"Retrain Linear SVM on train+val with best C, evaluate on test, print final test accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) RBF SVM — **YOU implement** tuning over C and gamma on validation\n",
    "\n",
    "**Goal:** Build `StandardScaler → SVC(kernel='rbf')` and tune over a grid of **C** and **gamma**.\n",
    "\n",
    "**TODO E:** Write the nested loop over C and gamma, call `evaluate_model`, and track the best pair by **validation accuracy**.\n",
    "\n",
    "**TODO F:** After selecting the best `(C, gamma)`, **retrain on TRAIN+VAL** and evaluate once on **TEST**.\n",
    "\n",
    "**Hints:**\n",
    "- Start with a small grid, then expand near the best region if needed.\n",
    "- Example grids: `C in [0.1, 1, 10, 100]`, `gamma in ['scale', 0.001, 0.01, 0.1]` (you may adjust)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_grid_rbf = [0.1, 1, 10, 100]            # you may modify\n",
    "gamma_grid = [\"scale\", 0.001, 0.01, 0.1]  # you may modify\n",
    "\n",
    "best_rbf = None\n",
    "best_params_rbf = None\n",
    "\n",
    "#### YOUR CODE HERE (TODO E): nested loop over (C, gamma), build pipeline, call evaluate_model, track best by val_acc ####\n",
    "raise NotImplementedError(\"Implement RBF SVM tuning loop over (C, gamma) and select best by validation accuracy.\")\n",
    "\n",
    "# (TODO F) Retrain best RBF SVM on TRAIN+VAL and evaluate on TEST\n",
    "#### YOUR CODE HERE ####\n",
    "raise NotImplementedError(\"Retrain RBF SVM on train+val with best (C, gamma), evaluate on test, print final test accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) (Optional) PCA → SVM — **YOU implement**\n",
    "\n",
    "**Goal:** Insert `PCA` before SVM (Linear and/or RBF). Choose `k` via a target variance ratio.\n",
    "\n",
    "**TODO G:**\n",
    "1. Fit a temporary PCA on **TRAIN** only to compute cumulative explained variance and select `k` for a target ratio (e.g., 0.95).\n",
    "2. Build a pipeline `StandardScaler → PCA(n_components=k) → SVC(...)`.\n",
    "3. Repeat tuning (C for Linear; C & gamma for RBF) using the **validation** set.\n",
    "4. Retrain the best PCA+SVM model(s) on **TRAIN+VAL** and evaluate once on **TEST**.\n",
    "\n",
    "**Hints:**\n",
    "- Use `PCA(svd_solver='full', whiten=False, random_state=RANDOM_STATE)`.\n",
    "- Compute `k` with `np.cumsum(pca_tmp.explained_variance_ratio_)` and `np.searchsorted`.\n",
    "- Report `k`, chosen hyperparameters, and test accuracy.\n",
    "- Be careful to avoid data leakage: fit PCA only on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pca = False   # set True to run PCA experiments\n",
    "variance_ratio = 0.95\n",
    "\n",
    "if use_pca:\n",
    "    #### YOUR CODE HERE (TODO G): determine k from TRAIN only ####\n",
    "    # pca_tmp = PCA(svd_solver='full', whiten=False, random_state=RANDOM_STATE)\n",
    "    # pca_tmp.fit(X_tr)\n",
    "    # cum = np.cumsum(pca_tmp.explained_variance_ratio_)\n",
    "    # k = int(np.searchsorted(cum, variance_ratio) + 1)\n",
    "    # print(f\"PCA: retaining ~{variance_ratio*100:.0f}% variance ⇒ k={k} components\")\n",
    "\n",
    "    #### YOUR CODE HERE: build pipelines with PCA + SVM; tune on VAL; retrain on TR+VAL; evaluate on TEST ####\n",
    "    raise NotImplementedError(\"Implement PCA→SVM experiments as described.\")\n",
    "else:\n",
    "    print(\"Skipped PCA experiments. Set use_pca=True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) What to include in your PDF report\n",
    "- Final **test accuracy** for:\n",
    "  - Linear SVM (best C)\n",
    "  - RBF SVM (best C, gamma)\n",
    "  - (Optional) PCA + SVM variants (report k)\n",
    "- The **chosen hyperparameters** (selected by validation accuracy)\n",
    "- Short discussion of how **C** and **gamma** affected performance\n",
    "- If PCA used: effect on accuracy and runtime\n",
    "- (Optional) confusion matrices for best models\n",
    "\n",
    "**Tip:** Keep code and results well organized so we can follow your steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_a5",
   "language": "python",
   "name": "venv_a5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
